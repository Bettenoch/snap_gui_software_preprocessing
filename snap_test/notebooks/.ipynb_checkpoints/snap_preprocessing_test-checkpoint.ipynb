{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26c9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.warp import transform_bounds, calculate_default_transform\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats, ndimage\n",
    "from shapely.geometry import shape, mapping\n",
    "import json\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817124e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "GEE_PROJECT = 'knowledgecraft'\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=GEE_PROJECT)\n",
    "    print(\"‚úì Earth Engine already initialized\")\n",
    "except Exception as e:\n",
    "    print(\"Authenticating Earth Engine...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=GEE_PROJECT)\n",
    "    print(\"‚úì Earth Engine initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36599ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the SNAP-preprocessed image\n",
    "SNAP_GEOTIFF = find_geotiff()\n",
    "print(f\"üìÅ Found SNAP GeoTIFF: {SNAP_GEOTIFF}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2153a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_metadata(tif_path: Path) -> Dict:\n",
    "    \"\"\"Extract and validate GeoTIFF metadata.\"\"\"\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        metadata = {\n",
    "            'path': str(tif_path),\n",
    "            'crs': str(src.crs),\n",
    "            'epsg': src.crs.to_epsg() if src.crs else None,\n",
    "            'bands': src.count,\n",
    "            'width': src.width,\n",
    "            'height': src.height,\n",
    "            'dtypes': src.dtypes,\n",
    "            'nodata': src.nodatavals,\n",
    "            'bounds': src.bounds,\n",
    "            'transform': src.transform,\n",
    "            'resolution': (src.transform[0], abs(src.transform[4])),\n",
    "            'units': src.units,\n",
    "            'descriptions': src.descriptions\n",
    "        }\n",
    "        \n",
    "        # Check if projected\n",
    "        metadata['is_projected'] = src.crs is not None and not src.crs.is_geographic\n",
    "        \n",
    "        # Estimate size in MB\n",
    "        metadata['size_mb'] = (src.width * src.height * src.count * \n",
    "                               np.dtype(src.dtypes[0]).itemsize) / (1024 * 1024)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# Inspect SNAP image\n",
    "snap_meta = inspect_metadata(SNAP_GEOTIFF)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä SNAP PREPROCESSING METADATA\")\n",
    "print(\"=\"*60)\n",
    "for key, value in snap_meta.items():\n",
    "    if key not in ['transform', 'bounds']:\n",
    "        print(f\"{key:20s}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GEOJSON = False  # Set to True if you have a GeoJSON ROI\n",
    "GEOJSON_PATH = \"roi.geojson\"  # Path to your GeoJSON file\n",
    "CLIP_SIZE = 512  # Patch size if not using GeoJSON (pixels)\n",
    "USE_FULL_IMAGE = False  # Set to True to analyze entire image\n",
    "\n",
    "def load_roi_geometry(geojson_path: str):\n",
    "    \"\"\"Load ROI from GeoJSON file.\"\"\"\n",
    "    with open(geojson_path, 'r') as f:\n",
    "        geojson = json.load(f)\n",
    "    \n",
    "    if geojson['type'] == 'FeatureCollection':\n",
    "        return shape(geojson['features'][0]['geometry'])\n",
    "    else:\n",
    "        return shape(geojson)\n",
    "\n",
    "def get_clip_window(src, clip_size: int) -> Tuple[Window, any]:\n",
    "    \"\"\"Calculate centered clip window.\"\"\"\n",
    "    window_size = min(clip_size, src.width, src.height)\n",
    "    center_col = src.width // 2\n",
    "    center_row = src.height // 2\n",
    "    col_off = int(center_col - window_size // 2)\n",
    "    row_off = int(center_row - window_size // 2)\n",
    "    \n",
    "    win = Window(col_off, row_off, window_size, window_size)\n",
    "    transform = src.window_transform(win)\n",
    "    \n",
    "    return win, transform\n",
    "\n",
    "# Load and clip data\n",
    "with rasterio.open(SNAP_GEOTIFF) as src:\n",
    "    if USE_GEOJSON and os.path.exists(GEOJSON_PATH):\n",
    "        print(f\"üìç Using ROI from: {GEOJSON_PATH}\")\n",
    "        roi_geom = load_roi_geometry(GEOJSON_PATH)\n",
    "        clipped_data, clipped_transform = mask(src, [roi_geom], crop=True, filled=False)\n",
    "        clip_bounds = roi_geom.bounds\n",
    "        clip_method = \"geojson\"\n",
    "        \n",
    "    elif USE_FULL_IMAGE:\n",
    "        print(\"üó∫Ô∏è Using full image\")\n",
    "        clipped_data = src.read(masked=True)\n",
    "        clipped_transform = src.transform\n",
    "        clip_bounds = src.bounds\n",
    "        clip_method = \"full\"\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚úÇÔ∏è Clipping centered {CLIP_SIZE}x{CLIP_SIZE} patch\")\n",
    "        win, clipped_transform = get_clip_window(src, CLIP_SIZE)\n",
    "        clipped_data = src.read(window=win, masked=True)\n",
    "        clip_bounds = src.window_bounds(win)\n",
    "        clip_method = \"centered\"\n",
    "    \n",
    "    # Convert to float32 for processing\n",
    "    clipped_data = clipped_data.astype('float32')\n",
    "    profile = src.profile.copy()\n",
    "\n",
    "# Update profile for clipped data\n",
    "profile.update({\n",
    "    'height': clipped_data.shape[1],\n",
    "    'width': clipped_data.shape[2],\n",
    "    'transform': clipped_transform\n",
    "})\n",
    "\n",
    "print(f\"\\n‚úÖ Clipped data shape: {clipped_data.shape}\")\n",
    "print(f\"   Method: {clip_method}\")\n",
    "print(f\"   Bounds: {clip_bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c85e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_band_statistics(data: np.ma.MaskedArray, band_idx: int) -> Dict:\n",
    "    \"\"\"Compute comprehensive statistics for a single band.\"\"\"\n",
    "    band = data[band_idx]\n",
    "    mask = np.ma.getmaskarray(band)\n",
    "    valid_count = np.count_nonzero(~mask)\n",
    "    valid_pct = 100 * valid_count / band.size\n",
    "    \n",
    "    if valid_count == 0:\n",
    "        return {\n",
    "            'band': band_idx + 1,\n",
    "            'valid_pixels': 0,\n",
    "            'valid_pct': 0,\n",
    "            'status': '‚ùå NO VALID DATA'\n",
    "        }\n",
    "    \n",
    "    vals = band.compressed()\n",
    "    \n",
    "    # Basic statistics\n",
    "    stats_dict = {\n",
    "        'band': band_idx + 1,\n",
    "        'valid_pixels': valid_count,\n",
    "        'valid_pct': round(valid_pct, 2),\n",
    "        'min': round(float(vals.min()), 4),\n",
    "        'max': round(float(vals.max()), 4),\n",
    "        'mean': round(float(vals.mean()), 4),\n",
    "        'median': round(float(np.median(vals)), 4),\n",
    "        'std': round(float(vals.std()), 4),\n",
    "        'cv': round(float(vals.std() / vals.mean() if vals.mean() != 0 else 0), 4),\n",
    "    }\n",
    "    \n",
    "    # Data quality indicators\n",
    "    stats_dict['zeros_count'] = int(np.sum(vals == 0))\n",
    "    stats_dict['zeros_pct'] = round(100 * stats_dict['zeros_count'] / vals.size, 2)\n",
    "    stats_dict['negatives_pct'] = round(100 * np.sum(vals < 0) / vals.size, 2)\n",
    "    stats_dict['dynamic_range_db'] = round(10 * np.log10(vals.max() / vals.min()) if vals.min() > 0 else np.nan, 2)\n",
    "    \n",
    "    # Convert to dB if in linear scale\n",
    "    if vals.max() < 100:  # Likely linear power\n",
    "        db_vals = 10 * np.log10(vals + 1e-10)\n",
    "        stats_dict['mean_db'] = round(float(db_vals.mean()), 2)\n",
    "        stats_dict['median_db'] = round(float(np.median(db_vals)), 2)\n",
    "        stats_dict['expected_range'] = 'VV: -25 to 5 dB, VH: -30 to -5 dB'\n",
    "        \n",
    "        # Check if values are in expected range\n",
    "        if -30 <= stats_dict['mean_db'] <= 5:\n",
    "            stats_dict['range_check'] = '‚úÖ PASS'\n",
    "        else:\n",
    "            stats_dict['range_check'] = '‚ö†Ô∏è OUT OF EXPECTED RANGE'\n",
    "    \n",
    "    # Skewness and Kurtosis\n",
    "    stats_dict['skewness'] = round(float(stats.skew(vals)), 4)\n",
    "    stats_dict['kurtosis'] = round(float(stats.kurtosis(vals)), 4)\n",
    "    \n",
    "    return stats_dict\n",
    "\n",
    "# Compute statistics for all bands\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìà BAND STATISTICS & QUALITY METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "band_stats = []\n",
    "for b in range(clipped_data.shape[0]):\n",
    "    stats_dict = compute_band_statistics(clipped_data, b)\n",
    "    band_stats.append(stats_dict)\n",
    "\n",
    "df_stats = pd.DataFrame(band_stats)\n",
    "print(df_stats.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### üìä Quality Score Calculation\n",
    "\n",
    "# %%\n",
    "def calculate_quality_score(stats: Dict) -> Dict:\n",
    "    \"\"\"Calculate quality score based on multiple criteria.\"\"\"\n",
    "    score = 100\n",
    "    issues = []\n",
    "    \n",
    "    # Valid data percentage\n",
    "    if stats['valid_pct'] < 95:\n",
    "        deduction = (95 - stats['valid_pct']) * 0.5\n",
    "        score -= deduction\n",
    "        issues.append(f\"Low valid data: {stats['valid_pct']:.1f}%\")\n",
    "    \n",
    "    # Zero values\n",
    "    if stats['zeros_pct'] > 5:\n",
    "        score -= min(20, stats['zeros_pct'])\n",
    "        issues.append(f\"High zeros: {stats['zeros_pct']:.1f}%\")\n",
    "    \n",
    "    # Negative values (should be minimal)\n",
    "    if stats['negatives_pct'] > 0.1:\n",
    "        score -= min(15, stats['negatives_pct'] * 10)\n",
    "        issues.append(f\"Negative values: {stats['negatives_pct']:.1f}%\")\n",
    "    \n",
    "    # Dynamic range check\n",
    "    if 'dynamic_range_db' in stats and not np.isnan(stats['dynamic_range_db']):\n",
    "        if stats['dynamic_range_db'] < 20:\n",
    "            score -= 10\n",
    "            issues.append(f\"Low dynamic range: {stats['dynamic_range_db']:.1f} dB\")\n",
    "    \n",
    "    # Expected range check\n",
    "    if stats.get('range_check') == '‚ö†Ô∏è OUT OF EXPECTED RANGE':\n",
    "        score -= 15\n",
    "        issues.append(f\"Mean {stats.get('mean_db', 'N/A')} dB outside expected range\")\n",
    "    \n",
    "    score = max(0, score)\n",
    "    \n",
    "    if score >= 90:\n",
    "        grade = \"A - Excellent\"\n",
    "    elif score >= 80:\n",
    "        grade = \"B - Good\"\n",
    "    elif score >= 70:\n",
    "        grade = \"C - Acceptable\"\n",
    "    elif score >= 60:\n",
    "        grade = \"D - Poor\"\n",
    "    else:\n",
    "        grade = \"F - Fail\"\n",
    "    \n",
    "    return {\n",
    "        'score': round(score, 1),\n",
    "        'grade': grade,\n",
    "        'issues': issues\n",
    "    }\n",
    "\n",
    "# Calculate quality scores\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ QUALITY SCORING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, stats in enumerate(band_stats):\n",
    "    quality = calculate_quality_score(stats)\n",
    "    print(f\"\\nBand {stats['band']}:\")\n",
    "    print(f\"  Score: {quality['score']}/100 ({quality['grade']})\")\n",
    "    if quality['issues']:\n",
    "        print(f\"  Issues:\")\n",
    "        for issue in quality['issues']:\n",
    "            print(f\"    - {issue}\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ No issues detected\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b5d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_band_analysis(data: np.ma.MaskedArray, band_idx: int, stats: Dict):\n",
    "    \"\"\"Create comprehensive visualization for a single band.\"\"\"\n",
    "    band = data[band_idx].filled(np.nan)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    fig.suptitle(f'Band {band_idx + 1} Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Linear scale image\n",
    "    ax = axes[0, 0]\n",
    "    im1 = ax.imshow(band, cmap='gray', vmin=np.nanpercentile(band, 2), \n",
    "                    vmax=np.nanpercentile(band, 98))\n",
    "    ax.set_title('Linear Scale (2-98 percentile stretch)')\n",
    "    ax.axis('off')\n",
    "    plt.colorbar(im1, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # 2. dB scale image (if applicable)\n",
    "    ax = axes[0, 1]\n",
    "    if stats['max'] < 100:  # Linear power values\n",
    "        band_db = 10 * np.log10(band + 1e-10)\n",
    "        im2 = ax.imshow(band_db, cmap='gray', vmin=-25, vmax=0)\n",
    "        ax.set_title('dB Scale (-25 to 0 dB)')\n",
    "        plt.colorbar(im2, ax=ax, fraction=0.046, pad=0.04, label='dB')\n",
    "    else:\n",
    "        im2 = ax.imshow(band, cmap='viridis')\n",
    "        ax.set_title('Alternative Colormap')\n",
    "        plt.colorbar(im2, ax=ax, fraction=0.046, pad=0.04)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # 3. Histogram (linear)\n",
    "    ax = axes[1, 0]\n",
    "    valid_data = band[~np.isnan(band)].ravel()\n",
    "    ax.hist(valid_data, bins=100, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(stats['mean'], color='red', linestyle='--', linewidth=2, label=f\"Mean: {stats['mean']:.4f}\")\n",
    "    ax.axvline(stats['median'], color='orange', linestyle='--', linewidth=2, label=f\"Median: {stats['median']:.4f}\")\n",
    "    ax.set_xlabel('Backscatter (linear)')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Histogram - Linear Scale')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Histogram (dB if applicable)\n",
    "    ax = axes[1, 1]\n",
    "    if stats['max'] < 100:\n",
    "        db_data = 10 * np.log10(valid_data + 1e-10)\n",
    "        ax.hist(db_data, bins=100, color='forestgreen', alpha=0.7, edgecolor='black')\n",
    "        ax.axvline(stats.get('mean_db', 0), color='red', linestyle='--', \n",
    "                   linewidth=2, label=f\"Mean: {stats.get('mean_db', 0):.2f} dB\")\n",
    "        ax.set_xlabel('Backscatter (dB)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Histogram - dB Scale')\n",
    "        ax.legend()\n",
    "    else:\n",
    "        # Box plot for statistics\n",
    "        ax.boxplot(valid_data, vert=True)\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.set_title('Box Plot')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot all bands\n",
    "for b in range(clipped_data.shape[0]):\n",
    "    plot_band_analysis(clipped_data, b, band_stats[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c8aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_spatial_quality(data: np.ma.MaskedArray, band_idx: int) -> Dict:\n",
    "    \"\"\"Detect spatial artifacts like stripes, edge effects, and noise patterns.\"\"\"\n",
    "    band = data[band_idx].filled(np.nan)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Edge artifact detection (check border pixels)\n",
    "    border_size = 10\n",
    "    top_edge = band[:border_size, :]\n",
    "    bottom_edge = band[-border_size:, :]\n",
    "    left_edge = band[:, :border_size]\n",
    "    right_edge = band[:, -border_size:]\n",
    "    \n",
    "    edges = [top_edge, bottom_edge, left_edge, right_edge]\n",
    "    edge_means = [np.nanmean(e) for e in edges]\n",
    "    center_mean = np.nanmean(band[border_size:-border_size, border_size:-border_size])\n",
    "    \n",
    "    results['edge_anomaly'] = any(abs(em - center_mean) / center_mean > 0.3 for em in edge_means if not np.isnan(em))\n",
    "    \n",
    "    # Stripe detection (column-wise variation)\n",
    "    col_means = np.nanmean(band, axis=0)\n",
    "    col_variation = np.nanstd(col_means) / np.nanmean(col_means) if np.nanmean(col_means) != 0 else 0\n",
    "    results['stripe_indicator'] = col_variation\n",
    "    results['potential_stripes'] = col_variation > 0.15\n",
    "    \n",
    "    # Texture smoothness (Laplacian variance)\n",
    "    laplacian = ndimage.laplace(np.nan_to_num(band))\n",
    "    results['laplacian_variance'] = float(np.var(laplacian))\n",
    "    results['texture_quality'] = 'smooth' if results['laplacian_variance'] < 1000 else 'noisy'\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Assess spatial quality\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üó∫Ô∏è SPATIAL QUALITY ASSESSMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for b in range(clipped_data.shape[0]):\n",
    "    spatial_qa = assess_spatial_quality(clipped_data, b)\n",
    "    print(f\"\\nBand {b + 1}:\")\n",
    "    print(f\"  Edge artifacts: {'‚ö†Ô∏è DETECTED' if spatial_qa['edge_anomaly'] else '‚úÖ None'}\")\n",
    "    print(f\"  Stripe detection: {'‚ö†Ô∏è POTENTIAL' if spatial_qa['potential_stripes'] else '‚úÖ None'} \"\n",
    "          f\"(CV: {spatial_qa['stripe_indicator']:.4f})\")\n",
    "    print(f\"  Texture quality: {spatial_qa['texture_quality'].upper()} \"\n",
    "          f\"(Laplacian var: {spatial_qa['laplacian_variance']:.2f})\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPARE_WITH_GEE = True  # Set to False to skip GEE comparison\n",
    "\n",
    "if COMPARE_WITH_GEE:\n",
    "    try:\n",
    "        import ee\n",
    "        import geemap\n",
    "        \n",
    "        # Initialize Earth Engine\n",
    "        try:\n",
    "            ee.Initialize()\n",
    "            print(\"‚úÖ Earth Engine initialized successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Earth Engine initialization failed: {e}\")\n",
    "            print(\"Run: earthengine authenticate\")\n",
    "            COMPARE_WITH_GEE = False\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è Earth Engine not installed. Install with: pip install earthengine-api geemap\")\n",
    "        COMPARE_WITH_GEE = False\n",
    "\n",
    "# %% [markdown]\n",
    "# ### üåç Fetch Sentinel-1 from GEE\n",
    "\n",
    "# %%\n",
    "if COMPARE_WITH_GEE:\n",
    "    # Get bounds in WGS84\n",
    "    with rasterio.open(SNAP_GEOTIFF) as src:\n",
    "        if USE_GEOJSON and os.path.exists(GEOJSON_PATH):\n",
    "            roi_geom = load_roi_geometry(GEOJSON_PATH)\n",
    "            bounds_4326 = roi_geom.bounds\n",
    "        else:\n",
    "            bounds_4326 = transform_bounds(src.crs, \"EPSG:4326\", *clip_bounds)\n",
    "    \n",
    "    # Create GEE geometry\n",
    "    geom = ee.Geometry.Rectangle(list(bounds_4326))\n",
    "    \n",
    "    # Date range (adjust as needed - using 2023 as default)\n",
    "    START_DATE = '2023-01-01'\n",
    "    END_DATE = '2023-12-31'\n",
    "    \n",
    "    print(f\"\\nüåç Fetching Sentinel-1 from GEE...\")\n",
    "    print(f\"   Date range: {START_DATE} to {END_DATE}\")\n",
    "    print(f\"   Bounds: {bounds_4326}\")\n",
    "    \n",
    "    # Build S1 collection\n",
    "    s1_collection = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "                     .filterBounds(geom)\n",
    "                     .filterDate(START_DATE, END_DATE)\n",
    "                     .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "                     .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "                     .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')))\n",
    "    \n",
    "    # Get collection size\n",
    "    collection_size = s1_collection.size().getInfo()\n",
    "    print(f\"   Found {collection_size} Sentinel-1 images\")\n",
    "    \n",
    "    if collection_size == 0:\n",
    "        print(\"‚ö†Ô∏è No Sentinel-1 images found for specified parameters\")\n",
    "        COMPARE_WITH_GEE = False\n",
    "    else:\n",
    "        # Use median composite (or first image)\n",
    "        USE_MEDIAN = True  # Set to False to use first image only\n",
    "        \n",
    "        if USE_MEDIAN:\n",
    "            s1_image = s1_collection.select(['VV', 'VH']).median()\n",
    "            print(\"   Using: Median composite\")\n",
    "        else:\n",
    "            s1_image = s1_collection.select(['VV', 'VH']).first()\n",
    "            print(\"   Using: First image\")\n",
    "        \n",
    "        # Download to local file\n",
    "        GEE_OUTPUT = \"gee_s1_comparison.tif\"\n",
    "        \n",
    "        print(f\"\\nüì• Downloading GEE image to: {GEE_OUTPUT}\")\n",
    "        print(\"   This may take a few minutes...\")\n",
    "        \n",
    "        try:\n",
    "            # Use geemap to download\n",
    "            geemap.ee_export_image(\n",
    "                s1_image,\n",
    "                filename=GEE_OUTPUT,\n",
    "                scale=10,\n",
    "                region=geom,\n",
    "                file_per_band=False\n",
    "            )\n",
    "            print(f\"‚úÖ Downloaded: {GEE_OUTPUT}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Download failed: {e}\")\n",
    "            print(\"\\nAlternative: Export to Google Drive\")\n",
    "            print(\"Run this in a separate cell:\")\n",
    "            print(f\"\"\"\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=s1_image,\n",
    "    description='gee_s1_comparison',\n",
    "    region=geom.getInfo()['coordinates'],\n",
    "    scale=10,\n",
    "    fileFormat='GeoTIFF'\n",
    ")\n",
    "task.start()\n",
    "print(\"Task started - check Google Drive\")\n",
    "            \"\"\")\n",
    "            COMPARE_WITH_GEE = False\n",
    "\n",
    "# %% [markdown]\n",
    "# ### üìä Compare SNAP vs GEE\n",
    "\n",
    "# %%\n",
    "if COMPARE_WITH_GEE and os.path.exists(\"gee_s1_comparison.tif\"):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä SNAP vs GEE COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load GEE data\n",
    "    with rasterio.open(\"gee_s1_comparison.tif\") as gee_src:\n",
    "        gee_data = gee_src.read(masked=True).astype('float32')\n",
    "        gee_meta = inspect_metadata(Path(\"gee_s1_comparison.tif\"))\n",
    "    \n",
    "    print(\"\\nGEE Image Info:\")\n",
    "    print(f\"  Bands: {gee_meta['bands']}\")\n",
    "    print(f\"  Shape: {gee_data.shape}\")\n",
    "    print(f\"  CRS: {gee_meta['crs']}\")\n",
    "    \n",
    "    # Compare band by band\n",
    "    num_bands = min(clipped_data.shape[0], gee_data.shape[0])\n",
    "    \n",
    "    for b in range(num_bands):\n",
    "        snap_band = clipped_data[b].filled(np.nan)\n",
    "        gee_band = gee_data[b].filled(np.nan)\n",
    "        \n",
    "        # Ensure same shape (resample if needed)\n",
    "        if snap_band.shape != gee_band.shape:\n",
    "            print(f\"\\n‚ö†Ô∏è Band {b+1}: Shape mismatch - SNAP {snap_band.shape} vs GEE {gee_band.shape}\")\n",
    "            from scipy.ndimage import zoom\n",
    "            zoom_factors = (snap_band.shape[0] / gee_band.shape[0], \n",
    "                           snap_band.shape[1] / gee_band.shape[1])\n",
    "            gee_band = zoom(gee_band, zoom_factors, order=1)\n",
    "            print(f\"   Resampled GEE to match SNAP shape\")\n",
    "        \n",
    "        # Calculate difference\n",
    "        diff = snap_band - gee_band\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"\\nBand {b+1} Comparison:\")\n",
    "        print(f\"  SNAP  - Mean: {np.nanmean(snap_band):.4f}, Std: {np.nanstd(snap_band):.4f}\")\n",
    "        print(f\"  GEE   - Mean: {np.nanmean(gee_band):.4f}, Std: {np.nanstd(gee_band):.4f}\")\n",
    "        print(f\"  Diff  - Mean: {np.nanmean(diff):.4f}, Std: {np.nanstd(diff):.4f}\")\n",
    "        print(f\"  RMSE: {np.sqrt(np.nanmean(diff**2)):.4f}\")\n",
    "        print(f\"  Correlation: {np.corrcoef(snap_band[~np.isnan(snap_band)].ravel(), gee_band[~np.isnan(gee_band)].ravel())[0,1]:.4f}\")\n",
    "        \n",
    "        # Visualize comparison\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle(f'Band {b+1}: SNAP vs GEE Comparison', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # SNAP\n",
    "        vmin, vmax = np.nanpercentile(snap_band, [2, 98])\n",
    "        im1 = axes[0, 0].imshow(snap_band, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        axes[0, 0].set_title('SNAP Preprocessed')\n",
    "        axes[0, 0].axis('off')\n",
    "        plt.colorbar(im1, ax=axes[0, 0], fraction=0.046)\n",
    "        \n",
    "        # GEE\n",
    "        im2 = axes[0, 1].imshow(gee_band, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        axes[0, 1].set_title('GEE Preprocessed')\n",
    "        axes[0, 1].axis('off')\n",
    "        plt.colorbar(im2, ax=axes[0, 1], fraction=0.046)\n",
    "        \n",
    "        # Difference\n",
    "        diff_lim = np.nanpercentile(np.abs(diff), 95)\n",
    "        im3 = axes[0, 2].imshow(diff, cmap='RdBu_r', vmin=-diff_lim, vmax=diff_lim)\n",
    "        axes[0, 2].set_title('Difference (SNAP - GEE)')\n",
    "        axes[0, 2].axis('off')\n",
    "        plt.colorbar(im3, ax=axes[0, 2], fraction=0.046)\n",
    "        \n",
    "        # Histograms\n",
    "        axes[1, 0].hist(snap_band[~np.isnan(snap_band)].ravel(), bins=50, \n",
    "                        alpha=0.7, label='SNAP', color='blue')\n",
    "        axes[1, 0].hist(gee_band[~np.isnan(gee_band)].ravel(), bins=50, \n",
    "                        alpha=0.7, label='GEE', color='red')\n",
    "        axes[1, 0].set_xlabel('Backscatter (linear)')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        axes[1, 0].set_title('Value Distribution')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Scatter plot\n",
    "        snap_flat = snap_band[~np.isnan(snap_band) & ~np.isnan(gee_band)].ravel()\n",
    "        gee_flat = gee_band[~np.isnan(snap_band) & ~np.isnan(gee_band)].ravel()\n",
    "        axes[1, 1].scatter(gee_flat, snap_flat, alpha=0.1, s=1)\n",
    "        axes[1, 1].plot([gee_flat.min(), gee_flat.max()], \n",
    "                        [gee_flat.min(), gee_flat.max()], \n",
    "                        'r--', linewidth=2, label='1:1 line')\n",
    "        axes[1, 1].set_xlabel('GEE Backscatter')\n",
    "        axes[1, 1].set_ylabel('SNAP Backscatter')\n",
    "        axes[1, 1].set_title('Correlation Plot')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Difference histogram\n",
    "        axes[1, 2].hist(diff[~np.isnan(diff)].ravel(), bins=50, \n",
    "                        color='purple', alpha=0.7)\n",
    "        axes[1, 2].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "        axes[1, 2].set_xlabel('Difference (SNAP - GEE)')\n",
    "        axes[1, 2].set_ylabel('Frequency')\n",
    "        axes[1, 2].set_title('Difference Distribution')\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "\n",
    "elif COMPARE_WITH_GEE:\n",
    "    print(\"\\n‚ö†Ô∏è GEE comparison image not found. Please download it first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quality_report(band_stats: list, output_file: str = \"quality_report.txt\"):\n",
    "    \"\"\"Generate comprehensive quality assessment report.\"\"\"\n",
    "    \n",
    "    report_lines = []\n",
    "    report_lines.append(\"=\"*80)\n",
    "    report_lines.append(\"SENTINEL-1 SNAP PREPROCESSING QUALITY ASSESSMENT REPORT\")\n",
    "    report_lines.append(\"=\"*80)\n",
    "    report_lines.append(f\"\\nImage: {SNAP_GEOTIFF}\")\n",
    "    report_lines.append(f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report_lines.append(f\"Clipping Method: {clip_method}\")\n",
    "    report_lines.append(f\"\\nImage Metadata:\")\n",
    "    report_lines.append(f\"  CRS: {snap_meta['crs']}\")\n",
    "    report_lines.append(f\"  Bands: {snap_meta['bands']}\")\n",
    "    report_lines.append(f\"  Resolution: {snap_meta['resolution'][0]}m x {snap_meta['resolution'][1]}m\")\n",
    "    report_lines.append(f\"  Dimensions: {snap_meta['width']} x {snap_meta['height']} pixels\")\n",
    "    report_lines.append(f\"  Size: {snap_meta['size_mb']:.2f} MB\")\n",
    "    \n",
    "    report_lines.append(f\"\\n{'='*80}\")\n",
    "    report_lines.append(\"QUALITY ASSESSMENT SUMMARY\")\n",
    "    report_lines.append(\"=\"*80)\n",
    "    \n",
    "    overall_scores = []\n",
    "    \n",
    "    for idx, stats in enumerate(band_stats):\n",
    "        quality = calculate_quality_score(stats)\n",
    "        overall_scores.append(quality['score'])\n",
    "        \n",
    "        report_lines.append(f\"\\n{'‚îÄ'*80}\")\n",
    "        report_lines.append(f\"Band {stats['band']} Quality Assessment\")\n",
    "        report_lines.append(f\"{'‚îÄ'*80}\")\n",
    "        report_lines.append(f\"Quality Score: {quality['score']}/100 ({quality['grade']})\")\n",
    "        report_lines.append(f\"\\nKey Metrics:\")\n",
    "        report_lines.append(f\"  Valid Pixels: {stats['valid_pct']:.2f}%\")\n",
    "        report_lines.append(f\"  Mean (linear): {stats['mean']:.4f}\")\n",
    "        if 'mean_db' in stats:\n",
    "            report_lines.append(f\"  Mean (dB): {stats['mean_db']:.2f} dB\")\n",
    "        report_lines.append(f\"  Std Dev: {stats['std']:.4f}\")\n",
    "        report_lines.append(f\"  Coefficient of Variation: {stats['cv']:.4f}\")\n",
    "        report_lines.append(f\"  Dynamic Range: {stats.get('dynamic_range_db', 'N/A')} dB\")\n",
    "        report_lines.append(f\"  Zeros: {stats['zeros_pct']:.2f}%\")\n",
    "        report_lines.append(f\"  Negatives: {stats['negatives_pct']:.2f}%\")\n",
    "        \n",
    "        if quality['issues']:\n",
    "            report_lines.append(f\"\\nIdentified Issues:\")\n",
    "            for issue in quality['issues']:\n",
    "                report_lines.append(f\"  ‚ö†Ô∏è {issue}\")\n",
    "        else:\n",
    "            report_lines.append(f\"\\n‚úÖ No quality issues detected\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    avg_score = np.mean(overall_scores)\n",
    "    report_lines.append(f\"\\n{'='*80}\")\n",
    "    report_lines.append(\"OVERALL ASSESSMENT\")\n",
    "    report_lines.append(\"=\"*80)\n",
    "    report_lines.append(f\"Average Quality Score: {avg_score:.1f}/100\")\n",
    "    \n",
    "    if avg_score >= 90:\n",
    "        assessment = \"EXCELLENT - Image is production-ready\"\n",
    "        emoji = \"üü¢\"\n",
    "    elif avg_score >= 80:\n",
    "        assessment = \"GOOD - Image is suitable for most applications\"\n",
    "        emoji = \"üü¢\"\n",
    "    elif avg_score >= 70:\n",
    "        assessment = \"ACCEPTABLE - Image may have minor issues\"\n",
    "        emoji = \"üü°\"\n",
    "    elif avg_score >= 60:\n",
    "        assessment = \"POOR - Image has significant quality issues\"\n",
    "        emoji = \"üü†\"\n",
    "    else:\n",
    "        assessment = \"FAIL - Image quality is insufficient\"\n",
    "        emoji = \"üî¥\"\n",
    "    \n",
    "    report_lines.append(f\"\\n{emoji} {assessment}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    report_lines.append(f\"\\n{'='*80}\")\n",
    "    report_lines.append(\"RECOMMENDATIONS\")\n",
    "    report_lines.append(\"=\"*80)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    for stats in band_stats:\n",
    "        if stats['zeros_pct'] > 5:\n",
    "            recommendations.append(\"‚Ä¢ High percentage of zero values detected - verify thermal noise removal settings\")\n",
    "        if stats.get('negatives_pct', 0) > 0.1:\n",
    "            recommendations.append(\"‚Ä¢ Negative values present - check calibration parameters\")\n",
    "        if stats.get('valid_pct', 100) < 95:\n",
    "            recommendations.append(\"‚Ä¢ Low valid pixel percentage - review masking and nodata handling\")\n",
    "        if stats.get('range_check') == '‚ö†Ô∏è OUT OF EXPECTED RANGE':\n",
    "            recommendations.append(\"‚Ä¢ Backscatter values outside expected range - verify calibration type (sigma0/gamma0)\")\n",
    "    \n",
    "    if not recommendations:\n",
    "        recommendations.append(\"‚úÖ No critical issues detected - preprocessing appears successful\")\n",
    "    \n",
    "    for rec in set(recommendations):  # Remove duplicates\n",
    "        report_lines.append(rec)\n",
    "    \n",
    "    report_lines.append(f\"\\n{'='*80}\")\n",
    "    report_lines.append(\"END OF REPORT\")\n",
    "    report_lines.append(\"=\"*80)\n",
    "    \n",
    "    # Write to file\n",
    "    report_text = \"\\n\".join(report_lines)\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    print(report_text)\n",
    "    print(f\"\\nüíæ Report saved to: {output_file}\")\n",
    "    \n",
    "    return report_text\n",
    "\n",
    "# Generate report\n",
    "quality_report = generate_quality_report(band_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e785799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_speckle_noise(data: np.ma.MaskedArray, band_idx: int, window_size: int = 7):\n",
    "    \"\"\"Assess speckle noise using local statistics.\"\"\"\n",
    "    band = data[band_idx].filled(np.nan)\n",
    "    \n",
    "    # Calculate local mean and std using uniform filter\n",
    "    from scipy.ndimage import uniform_filter\n",
    "    \n",
    "    local_mean = uniform_filter(band, size=window_size, mode='constant', cval=np.nan)\n",
    "    local_sq_mean = uniform_filter(band**2, size=window_size, mode='constant', cval=np.nan)\n",
    "    local_std = np.sqrt(np.maximum(local_sq_mean - local_mean**2, 0))\n",
    "    \n",
    "    # Coefficient of variation\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        local_cv = local_std / local_mean\n",
    "    \n",
    "    # Speckle index (lower is better)\n",
    "    speckle_index = np.nanmean(local_cv)\n",
    "    \n",
    "    results = {\n",
    "        'speckle_index': float(speckle_index),\n",
    "        'quality': 'excellent' if speckle_index < 0.2 else 'good' if speckle_index < 0.4 else 'poor'\n",
    "    }\n",
    "    \n",
    "    return results, local_cv\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üî¨ ADVANCED SPECKLE ASSESSMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for b in range(clipped_data.shape[0]):\n",
    "    speckle_results, cv_map = assess_speckle_noise(clipped_data, b)\n",
    "    print(f\"\\nBand {b+1}:\")\n",
    "    print(f\"  Speckle Index: {speckle_results['speckle_index']:.4f}\")\n",
    "    print(f\"  Quality: {speckle_results['quality'].upper()}\")\n",
    "    \n",
    "    # Visualize speckle map\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle(f'Band {b+1}: Speckle Assessment', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Original band\n",
    "    band_data = clipped_data[b].filled(np.nan)\n",
    "    im1 = axes[0].imshow(band_data, cmap='gray', \n",
    "                         vmin=np.nanpercentile(band_data, 2),\n",
    "                         vmax=np.nanpercentile(band_data, 98))\n",
    "    axes[0].set_title('Original Band')\n",
    "    axes[0].axis('off')\n",
    "    plt.colorbar(im1, ax=axes[0], fraction=0.046)\n",
    "    \n",
    "    # Coefficient of Variation (speckle indicator)\n",
    "    im2 = axes[1].imshow(cv_map, cmap='hot', vmin=0, vmax=0.5)\n",
    "    axes[1].set_title('Coefficient of Variation (Speckle Indicator)')\n",
    "    axes[1].axis('off')\n",
    "    plt.colorbar(im2, ax=axes[1], fraction=0.046, label='CV')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNAP Quality Analysis",
   "language": "python",
   "name": "snap_qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
